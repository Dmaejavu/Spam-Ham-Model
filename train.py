# -*- coding: utf-8 -*-
"""SMS-Spam-Morales-Oro.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OkufOp8UlIjHbeHCTpJ_WmC6P8QzNrwJ

Morales, A.
Oro, D.M.
"""

import pandas as pd
import os as os
import joblib as joblib

# Load and clean the dataset
df = pd.read_csv('spam.csv', encoding='latin-1')[['v1', 'v2']]
df.columns = ['label', 'text']

# Simple normalization
df['text'] = df['text'].str.lower()

# prompt: print number of ham and spam separate

print(df['label'].value_counts())

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer

# Split data
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.3, random_state=42)

# Convert text to numeric features
vectorizer = CountVectorizer()
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

# Cell 3: Train and Evaluate the Model with Visual Output
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

# Train the model
model = MultinomialNB()
model.fit(X_train_vec, y_train)

# Make predictions
y_pred = model.predict(X_test_vec)

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f" Accuracy: {accuracy:.4f}")

# Classification Report as DataFrame
report_dict = classification_report(y_test, y_pred, output_dict=True)
report_df = pd.DataFrame(report_dict).transpose()

# Round values for cleaner display
report_df[['precision', 'recall', 'f1-score']] = report_df[['precision', 'recall', 'f1-score']].round(4)

# Display the classification report as a table
print("\n Classification Report:")
print(report_df)

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred, labels=['ham', 'spam'])
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['ham', 'spam'], yticklabels=['ham', 'spam'])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.tight_layout()
plt.show()

try: 
    os.makedirs("models", exist_ok=True)
    joblib.dump(model, "models/knn_model.joblib")
    joblib.dump(vectorizer, "models/vectorizer.joblib")
    print("\n Success")
except: 
    print(f"Failed to make model : {e}")


"""1. The model's accuracy in identifying 'ham' and 'spam' messages is 0.9821.
2. The 'ham' class had higher recall (0.9966) than 'spam' (0.8858). This means the model was better in identifying all the 'ham' messages than the 'spam' messages.
3. Lowercasing the text that is fed into the model helps it treat the words with different capitalization the same (e.g., "Hello" and "hello" are seen as the same word), which simplifies the data for training and the actual testing.
4. I learned that even with simple text processing, machine learning can effectively classify text by learning patterns from the words and with the help of other tools, we can categorize these text for our usage.
5. To improve or takenote, imbalances in the database between the ham and spam, it'll affect the accuracy, I could use more advanced text processing (like finding word roots), try different ways to convert text to numbers (like TF-IDF), test other models that can be more efficient and accurate than the one we are using, or just adjust the current model's settings.

Tackling The Datainbalances between the spam and ham
"""

